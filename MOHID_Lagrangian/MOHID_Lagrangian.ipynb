{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOHID Lagrangian\n",
    "\n",
    "This Jupyter Notebook aims to help implement and run the MOHID Lagrangian model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Note 1**: Execute each cell through the <button class=\"btn btn-default btn-xs\"><i class=\"icon-play fa fa-play\"></i></button> button from the top MENU (or keyboard shortcut `Shift` + `Enter`).<br>\n",
    "<br>\n",
    "**Note 2**: Use the Kernel and Cell menus to restart the kernel and clear outputs.<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "- [1. Import required libraries](#1.-Import-required-libraries)\n",
    "- [2. Download CMEMS for the area of interest](#2.-Download-CMEMS-for-the-area-of-interest)\n",
    "    - [2.1 Draw a polygon to select the CMEMS area for download](#2.1-Draw-a-polygon-to-select-the-CMEMS-area-for-download)\n",
    "    - [2.2 Set CMEMS product, dates and depths](#2.2-Set-CMEMS-product,-dates-and-depths)\n",
    "    - [2.3 Download CMEMS](#2.3-Download-CMEMS)\n",
    "- [3. Define sources](#3.-Define-sources)\n",
    "    - [3.1 Load a NetCDF dataset](#3.1-Load-a-NetCDF-dataset)\n",
    "    - [3.2 Load a MOHID HDF5 dataset](#3.2-Load-a-MOHID-HDF5-dataset)\n",
    "    - [3.3 Draw markers on the map to define the source coordinates](#3.3-Draw-markers-on-the-map-to-define-the-source-coordinates)\n",
    "- [4. Setup MOHID Lagrangian xml input files](#4.-Setup-MOHID-Lagrangian-xml-input-files)\n",
    "    - [4.1 Parameter definitions](#4.1-Parameter-definitions)\n",
    "    - [4.2 Simulation definitions](#4.2-Simulation-definitions)\n",
    "    - [4.3 Source definitions](#4.3-Source-definitions)\n",
    "- [5. Run MOHID Lagrangian](#5.-Run-MOHID-Lagrangian)\n",
    "- [6. Visualize the final results](#6.-Visualize-the-final-results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from update_xml_case import *\n",
    "import copernicusmarine\n",
    "import os\n",
    "from ipyleaflet import Map, TileLayer, DrawControl, GeoJSON, Marker\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, to_hex\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import vtk\n",
    "import folium\n",
    "import matplotlib as mpl\n",
    "from folium.plugins import MeasureControl\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set run case\n",
    "name = \"Plastic_Case\"\n",
    "\n",
    "dirpath = \"run_cases\" \n",
    "\n",
    "xml_file_path = f\"{name}.xml\"\n",
    "\n",
    "# Construct the path and change the working directory\n",
    "os.chdir(os.path.join(dirpath, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download CMEMS for the area of interest\n",
    "Skip this step if you have another hydrodynamic dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Draw a polygon to select the CMEMS area for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ipyleaflet map centered at (0,0)\n",
    "m = Map(center=[0, 0], zoom=2)\n",
    "\n",
    "# Define WMTS Layer\n",
    "wmts_layer = TileLayer(\n",
    "    url=\"https://wmts.marine.copernicus.eu/teroWmts/?\"\n",
    "        \"service=WMTS&request=GetTile&version=1.0.0&\"\n",
    "        \"layer=GLOBAL_ANALYSISFORECAST_PHY_001_024/\"\n",
    "        \"cmems_mod_glo_phy-cur_anfc_0.083deg_P1M-m_202406/sea_water_velocity&\"\n",
    "        \"tilematrixset=EPSG:3857&tilematrix={z}&tilerow={y}&tilecol={x}&\"\n",
    "        \"format=image/png&transparent=True\",\n",
    "    name=\"Sea Water Velocity\"\n",
    ")\n",
    "\n",
    "# Add WMTS layer to the map\n",
    "m.add_layer(wmts_layer)\n",
    "\n",
    "# Create a DrawControl for user interaction\n",
    "draw_control = DrawControl(\n",
    "    polygon={},  # Empty dict disables polygon\n",
    "    rectangle={\"shapeOptions\": {\"color\": \"blue\"}},  # Enable rectangles\n",
    "    circle={},  # Empty dict disables circles\n",
    "    polyline={},  # Empty dict disables polylines\n",
    "    marker={}  # Empty dict disables markers\n",
    ")\n",
    "\n",
    "# Function to handle drawn shapes and print bounds\n",
    "def handle_draw(target, action, geo_json):\n",
    "    global min_lat, max_lat, min_lon, max_lon\n",
    "    \n",
    "    if action == \"created\":\n",
    "        \n",
    "        # Extract coordinates from the drawn shape\n",
    "        coords = geo_json[\"geometry\"][\"coordinates\"][0]\n",
    "\n",
    "        # Get min/max latitude and longitude\n",
    "        lats = [point[1] for point in coords]  \n",
    "        lons = [point[0] for point in coords]  \n",
    "\n",
    "        min_lat, max_lat = min(lats), max(lats)\n",
    "        min_lon, max_lon = min(lons), max(lons)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"âœ… Polygon Bounds:\")\n",
    "        print(f\"  - min_lon (West): {min_lon}\")\n",
    "        print(f\"  - min_lat (South): {min_lat}\")\n",
    "        print(f\"  - max_lon (East): {max_lon}\")\n",
    "        print(f\"  - max_lat (North): {max_lat}\")\n",
    "\n",
    "# Attach the handler correctly\n",
    "draw_control.on_draw(handle_draw)\n",
    "\n",
    "# Add DrawControl to the map\n",
    "m.add_control(draw_control)\n",
    "\n",
    "# Display the interactive map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Set CMEMS product, dates and depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.getcwd(),\"Boundary_Conditions\")\n",
    "\n",
    "#hourly instanataneous\n",
    "#product_id = \"cmems_mod_glo_phy_anfc_merged-uv_PT1H-i\"\n",
    "\n",
    "#6-hourly instanataneous\n",
    "#product_id = \"cmems_mod_glo_phy-cur_anfc_0.083deg_PT6H-i\"\n",
    "\n",
    "#daily mean\n",
    "product_id = \"cmems_mod_glo_phy-cur_anfc_0.083deg_P1D-m\"\n",
    "\n",
    "#fill in info for CMEMS download\n",
    "start = datetime.date(2024,1,1)\n",
    "end = datetime.date(2024,2,1)\n",
    "\n",
    "start_depth = 0.49402499198913574\n",
    "end_depth = 0.49402499198913574\n",
    "#end_depth = 5727.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Download CMEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "def download_file():\n",
    " \n",
    "        variable = ['uo','vo']            \n",
    "                                \n",
    "        copernicusmarine.subset(\n",
    "           dataset_id = product_id,\n",
    "           minimum_longitude = min_lon, maximum_longitude = max_lon,\n",
    "           minimum_latitude = min_lat, maximum_latitude = max_lat,\n",
    "           minimum_depth = start_depth, maximum_depth = end_depth, \n",
    "           start_datetime = str(start.strftime('%Y-%m-%d'))+' 00:00:00', \n",
    "           end_datetime = str(end.strftime('%Y-%m-%d'))+' 00:00:00',\n",
    "           variables = variable, \n",
    "           output_directory = output_dir,\n",
    "           output_filename = output_file_name,\n",
    "           netcdf3_compatible = True)\n",
    "                \n",
    "#####################################################\n",
    "     \n",
    "output_file_name = \"cmems_\"+str(start.strftime(\"%Y%m%d\")) + \"_\" + str(end.strftime(\"%Y%m%d\") + \".nc\")\n",
    "\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "download_file()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load a NetCDF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.getcwd(), \"Boundary_Conditions\")\n",
    "output_file_name = \"CMEMS_cur.nc\" #Load your own NetCDF instead of CMEMS, otherwise comment out this line\n",
    "CurFName = os.path.join(output_dir, output_file_name)\n",
    "dataset = xr.open_dataset(CurFName)\n",
    "\n",
    "CurFName = os.path.join(output_dir, output_file_name) \n",
    "# Open the datafile\n",
    "CurDS = xr.open_dataset(CurFName, engine=\"netcdf4\")\n",
    "\n",
    "U = dataset['uo'].isel(time=0).isel(depth=0).squeeze()  # Result is 2D: (lat, lon)\n",
    "V = dataset['vo'].isel(time=0).isel(depth=0).squeeze()  # Result is 2D: (lat, lon)\n",
    "\n",
    "# Show info of dataset\n",
    "CurDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Load a MOHID HDF5 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the output directory and file path\n",
    "output_dir = os.path.join(os.getcwd(), \"Boundary_Conditions\")\n",
    "output_file_name = \"Hydrodynamic_2_Surface.hdf5\"\n",
    "CurFName = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "# Open the HDF5 file using h5py and load data into NumPy arrays.\n",
    "with h5py.File(CurFName, 'r') as f:\n",
    "    # Access the 'Results' group for velocity data.\n",
    "    res_group = f['Results']\n",
    "    instant = \"00001\"  # Define the time instant.\n",
    "    vel_u_key = f\"velocity U_{instant}\"\n",
    "    vel_v_key = f\"velocity V_{instant}\"\n",
    "    \n",
    "    # Extract and squeeze the velocity modulus data.\n",
    "    velocity_u = np.squeeze(res_group['velocity U'][vel_u_key][-1,:,:])\n",
    "    velocity_v = np.squeeze(res_group['velocity V'][vel_v_key][-1,:,:])\n",
    "    \n",
    "    # Extract grid corner coordinates for longitude and latitude.\n",
    "    lon_corners = (f['Grid']['Longitude'][:,0])\n",
    "    lat_corners = (f['Grid']['Latitude'][0,:])\n",
    "\n",
    "velocity_u = velocity_u.T\n",
    "velocity_v = velocity_v.T\n",
    "\n",
    "# Compute the center values by averaging adjacent elements\n",
    "lon_center = (lon_corners[:-1] + lon_corners[1:]) / 2\n",
    "lat_center = (lat_corners[:-1] + lat_corners[1:]) / 2\n",
    "\n",
    "# Create an xarray Dataset with matching dimensions.\n",
    "dataset = xr.Dataset(\n",
    "    {\n",
    "        \"uo\": ((\"latitude\",\"longitude\"), velocity_u),\n",
    "        \"vo\": ((\"latitude\",\"longitude\"), velocity_v),\n",
    "    },\n",
    "    coords={\n",
    "        \"longitude\": lon_center,\n",
    "        \"latitude\": lat_center,\n",
    "    }\n",
    ")\n",
    "\n",
    "U = dataset['uo']\n",
    "V = dataset['vo']\n",
    "\n",
    "U = U.where((U > -99) & (U != 0), np.nan)\n",
    "V = V.where((V > -99) & (V != 0), np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Draw markers on the map to define the source coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Start timing\n",
    "# -------------------------------\n",
    "start_time = time.time()\n",
    "\n",
    "zi = np.sqrt(U**2 + V**2)  # Velocity magnitude, 2D array\n",
    "\n",
    "# -------------------------------\n",
    "# Optional Downsampling for large datasets\n",
    "# -------------------------------\n",
    "downsample_factor = 4  # Adjust as needed.\n",
    "zi = zi[::downsample_factor, ::downsample_factor]\n",
    "lon = dataset['longitude'].values[::downsample_factor]\n",
    "lat = dataset['latitude'].values[::downsample_factor]\n",
    "\n",
    "print(\"zi:\", zi.shape)\n",
    "print(\"Latitude size:\", lat.shape)\n",
    "print(\"Longitude size:\", lon.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# Get coordinate grids\n",
    "# -------------------------------\n",
    "LonGrid, LatGrid = np.meshgrid(lon, lat)\n",
    "        \n",
    "# -------------------------------\n",
    "# Precompute color mapping (vectorized)\n",
    "# -------------------------------\n",
    "colormap = plt.cm.viridis\n",
    "norm = Normalize(vmin=np.nanmin(zi), vmax=np.nanmax(zi))\n",
    "flat_colors = [to_hex(c) for c in colormap(norm(zi.values.ravel()))]\n",
    "colors = np.array(flat_colors).reshape(zi.shape)\n",
    "print(f\"Time spent on color mapping: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# -------------------------------\n",
    "# Precompute grid cell corners for GeoJSON layers\n",
    "# -------------------------------\n",
    "lon_sw = LonGrid[:-1, :-1]   # Southwest corner\n",
    "lon_se = LonGrid[:-1,  1:]   # Southeast corner\n",
    "lon_ne = LonGrid[1:,   1:]   # Northeast corner\n",
    "lon_nw = LonGrid[1:,  :-1]   # Northwest corner\n",
    "\n",
    "lat_sw = LatGrid[:-1, :-1]\n",
    "lat_se = LatGrid[:-1,  1:]\n",
    "lat_ne = LatGrid[1:,   1:]\n",
    "lat_nw = LatGrid[1:,  :-1]\n",
    "\n",
    "zi_cells = zi.values[:-1, :-1]\n",
    "print(\"zi_cells:\", zi_cells.shape)\n",
    "def generate_geojson_batches(batch_size=50):\n",
    "    \"\"\"\n",
    "    Yields GeoJSON FeatureCollections for each batch of grid cells.\n",
    "    Cells with NaN velocity magnitude are skipped.\n",
    "    \"\"\"\n",
    "    n_rows, n_cols = lon_sw.shape\n",
    "    for i in range(0, n_rows, batch_size):\n",
    "        for j in range(0, n_cols, batch_size):\n",
    "            i_end = min(i + batch_size, n_rows)\n",
    "            j_end = min(j + batch_size, n_cols)\n",
    "            features = []\n",
    "            for r in range(i, i_end):\n",
    "                for c in range(j, j_end):\n",
    "                    if np.isnan(zi_cells[r, c]):\n",
    "                        continue\n",
    "                    feature = {\n",
    "                        \"type\": \"Feature\",\n",
    "                        \"geometry\": {\n",
    "                            \"type\": \"Polygon\",\n",
    "                            \"coordinates\": [[\n",
    "                                [lon_sw[r, c], lat_sw[r, c]],\n",
    "                                [lon_se[r, c], lat_se[r, c]],\n",
    "                                [lon_ne[r, c], lat_ne[r, c]],\n",
    "                                [lon_nw[r, c], lat_nw[r, c]]\n",
    "                            ]]\n",
    "                        },\n",
    "                        \"properties\": {\n",
    "                            \"fill\": colors[r, c],\n",
    "                            \"stroke\": \"#000000\",\n",
    "                            \"fill-opacity\": 0.5,\n",
    "                            \"stroke-width\": 0.2\n",
    "                        }\n",
    "                    }\n",
    "                    features.append(feature)\n",
    "            if features:\n",
    "                yield {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "\n",
    "# -------------------------------\n",
    "# Create the map and add dataset layers\n",
    "# -------------------------------\n",
    "map_center = [(lat.min() + lat.max()) / 2, (lon.min() + lon.max()) / 2]\n",
    "m = Map(center=map_center, zoom=4)\n",
    "\n",
    "for batch_geojson in generate_geojson_batches():\n",
    "    geojson_layer = GeoJSON(\n",
    "        data=batch_geojson,\n",
    "        style_callback=lambda feature: {\n",
    "            \"fillColor\": feature[\"properties\"][\"fill\"],\n",
    "            \"color\": feature[\"properties\"][\"stroke\"],\n",
    "            \"weight\": feature[\"properties\"][\"stroke-width\"],\n",
    "            \"fillOpacity\": feature[\"properties\"][\"fill-opacity\"]\n",
    "        }\n",
    "    )\n",
    "    m.add_layer(geojson_layer)\n",
    "\n",
    "print(f\"Total time for GeoJSON layers: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# -------------------------------\n",
    "# Global store for drawn markers\n",
    "# -------------------------------\n",
    "# Dictionary mapping marker_id -> {'location': [lon, lat], 'name': str}\n",
    "markers_dict = {}\n",
    "marker_counter = 0  # Unique marker counter\n",
    "\n",
    "def ask_marker_name(marker, marker_id):\n",
    "    \"\"\"\n",
    "    Display a text input widget to ask for a marker name.\n",
    "    When confirmed, assign the name to the marker and update the global dictionary.\n",
    "    \"\"\"\n",
    "    name_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Enter source name',\n",
    "        description='Source name:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    confirm_button = widgets.Button(\n",
    "        description='Confirm',\n",
    "        disabled=False,\n",
    "        button_style='success'\n",
    "    )\n",
    "    \n",
    "    def on_button_clicked(b):\n",
    "        marker_name = name_input.value.strip()\n",
    "        if not marker_name:\n",
    "            marker_name = f\"Marker {marker_id}\"\n",
    "        # Attach the marker name\n",
    "        marker.marker_name = marker_name\n",
    "        # Update the marker entry with the name\n",
    "        markers_dict[marker_id]['name'] = marker_name\n",
    "        print(f\"Marker {marker_id} named '{marker_name}'\")\n",
    "        widget_box.close()  # Close the widget after confirmation\n",
    "        \n",
    "    confirm_button.on_click(on_button_clicked)\n",
    "    widget_box = widgets.VBox([name_input, confirm_button])\n",
    "    display(widget_box)\n",
    "\n",
    "def handle_draw(target, action, geo_json):\n",
    "    global marker_counter, markers_dict\n",
    "    \n",
    "    if action == \"created\":\n",
    "        coords = geo_json[\"geometry\"][\"coordinates\"]  # [lon, lat]\n",
    "        marker_id = marker_counter  # Assign an ID\n",
    "        marker_counter += 1\n",
    "        # Store with location and placeholder for marker name\n",
    "        markers_dict[marker_id] = {'location': [coords[1], coords[0]], 'name': None}\n",
    "    \n",
    "        # Create a draggable marker\n",
    "        custom_marker = Marker(location=[coords[1], coords[0]], draggable=True)\n",
    "        custom_marker.marker_id = marker_id  # Attach marker ID\n",
    "    \n",
    "        # Ask user to enter a name for the new marker\n",
    "        ask_marker_name(custom_marker, marker_id)\n",
    "    \n",
    "        # Function to update stored marker coordinates when moved\n",
    "        def on_location_change(change, m_id=marker_id):\n",
    "            new_location = change[\"new\"]  # New [lat, lon]\n",
    "            markers_dict[m_id]['location'] = [new_location[1], new_location[0]]\n",
    "            print(f\"Marker {m_id} moved to: {markers_dict[m_id]['location']}\")\n",
    "    \n",
    "        # Observe marker movement\n",
    "        custom_marker.observe(on_location_change, names=\"location\")\n",
    "    \n",
    "        # Add the new draggable marker to the map\n",
    "        m.add_layer(custom_marker)\n",
    "        \n",
    "        # Remove the default marker added by DrawControl\n",
    "        for layer in list(m.layers):\n",
    "            if isinstance(layer, GeoJSON) and layer.data.get(\"geometry\", {}).get(\"type\", \"\") == \"Point\":\n",
    "                m.remove_layer(layer)\n",
    "    \n",
    "    elif action == \"edited\":\n",
    "        print(\"Edit event received; marker updates are handled via the location observer.\")\n",
    "    \n",
    "    elif action == \"deleted\":\n",
    "        features = geo_json.get(\"features\", [])\n",
    "        if not features:\n",
    "            features = [geo_json]\n",
    "        for feature in features:\n",
    "            marker_id = feature.get(\"properties\", {}).get(\"marker_id\")\n",
    "            if marker_id is not None and marker_id in markers_dict:\n",
    "                print(f\"Deleted marker {marker_id} named '{markers_dict[marker_id]['name']}' at {markers_dict[marker_id]['location']}\")\n",
    "                markers_dict.pop(marker_id)\n",
    "        print(\"Current markers after deletion:\", markers_dict)\n",
    "\n",
    "draw_control = DrawControl()\n",
    "# For drawing tools we don't need, use empty dictionaries.\n",
    "draw_control.polygon   = {}\n",
    "draw_control.polyline  = {}\n",
    "draw_control.rectangle = {}\n",
    "draw_control.circle    = {}\n",
    "# Enable marker drawing button by assigning a non-empty dictionary.\n",
    "draw_control.marker    = {\"repeatMode\": False}\n",
    "\n",
    "draw_control.on_draw(handle_draw)\n",
    "m.add_control(draw_control)\n",
    "\n",
    "# -------------------------------\n",
    "# Display the map \n",
    "# -------------------------------\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Setup MOHID Lagrangian xml input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Parameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time limits (min and max time values in the dataset's 'time' variable)\n",
    "start, end = min(dataset['time'].values), max(dataset['time'].values)\n",
    "\n",
    "# Convert the numpy.datetime64 to a Python datetime object using pandas\n",
    "Start = pd.to_datetime(start) #Date of initial instant based on nc file\n",
    "End = pd.to_datetime(end) #Date of final instant based on nc file\n",
    "#Start = datetime.datetime(2024, 1, 1, 0, 0, 0)\n",
    "#End = datetime.datetime(2024, 1, 2, 0, 0, 0)\n",
    "\n",
    "Integrator = 2 #Integration Algorithm 1:Euler, 2:Multi-Step Euler, 3:RK4 (default=1)\n",
    "Threads = \"auto\" #Computation threads for shared memory computation (default=auto)\n",
    "OutputWriteTime = 86400 #Time out data (seconds)\n",
    "BufferSize = 86400 #control the amount of hydrodynamic data to store in RAM memory (seconds)\n",
    "\n",
    "# Run the update function\n",
    "update_parameter_definitions(xml_file_path,Start,End,Integrator,Threads,OutputWriteTime,BufferSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Simulation definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Get area limits\n",
    "# -------------------------------\n",
    "min_lat, max_lat = min(dataset['latitude'].values), max(dataset['latitude'].values)\n",
    "min_lon, max_lon = min(dataset['longitude'].values), max(dataset['longitude'].values)\n",
    "\n",
    "resolution = 8000 #metres (m)\n",
    "timestep = 180 #seconds (s)\n",
    "BoundingBoxMin = min_lon,min_lat,-1 #defines the corners of your simulation domain x,y,z (deg,deg,m)\n",
    "BoundingBoxMax = max_lon, max_lat,1 #defines the corners of your simulation domain x,y,z (deg,deg,m)\n",
    "VerticalVelMethod = 3 #1:From velocity fields, 2:Divergence based, 3:Disabled. Default = 1\n",
    "BathyminNetcdf = 0 #bathymetry is a property in the netcdf. 1:true, 0:false (computes from layer depth and openPoints. Default = 1\n",
    "RemoveLandTracer = 0 #Remove tracers on land 0:No, 1:Yes. Default = 1\n",
    "TracerMaxAge = 0 #maximum tracer age. Default = 0.0. read if > 0\n",
    "\n",
    "# Run the update function\n",
    "update_simulation_definitions(xml_file_path,resolution,timestep,BoundingBoxMin,BoundingBoxMax,VerticalVelMethod,BathyminNetcdf,RemoveLandTracer,TracerMaxAge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Source definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_seconds = 3600 #emission step in seconds\n",
    "rate_trcPerEmission = 5 #number of tracers emited every rate_seconds\n",
    "\n",
    "update_source_definitions(xml_file_path, markers_dict,rate_seconds,rate_trcPerEmission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run MOHID Lagrangian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirout = f\"{name}_out\"\n",
    "\n",
    "# Paths to executables and scripts\n",
    "tools = r\"../build/bin/RELEASE\"\n",
    "mohidlagrangian = os.path.join(tools, \"MOHIDLagrangian.exe\")\n",
    "\n",
    "preprocessor_dir = r\"../src/MOHIDLagrangianPreProcessor\"\n",
    "preprocessor = os.path.join(preprocessor_dir, \"MOHIDLagrangianPreProcessor.py\")\n",
    "\n",
    "postprocessor_dir = r\"../src/MOHIDLagrangianPostProcessor\"\n",
    "postprocessor = os.path.join(postprocessor_dir, \"MOHIDLagrangianPostprocessor.py\")\n",
    "\n",
    "# Manage output directory\n",
    "if os.path.exists(dirout):\n",
    "    shutil.rmtree(dirout)\n",
    "os.makedirs(dirout)\n",
    "\n",
    "# Copy XML configuration file\n",
    "shutil.copy(f\"{name}.xml\", dirout)\n",
    "\n",
    "# Run Preprocessing\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, preprocessor, \"-i\", f\"{dirout}/{name}.xml\", \"-o\", dirout],\n",
    "        check=True,\n",
    "    )\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Preprocessing failed.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Run Main Executable\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [mohidlagrangian, \"-i\", f\"{dirout}/{name}.xml\", \"-o\", dirout],\n",
    "        check=True,\n",
    "    )\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Execution of MOHIDLagrangian failed.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Run Postprocessing\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-W\", \"ignore\", postprocessor, \"-i\", f\"{name}.xml\", \"-o\", dirout],\n",
    "        check=True,\n",
    "    )\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Postprocessing failed.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visualize the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing VTU files.\n",
    "dirout = f\"{name}_out\"  # e.g., \"case_out\" or \"Plastic_Case_out\"\n",
    "\n",
    "# Use glob to find all files with the pattern '{name}_*.vtu' in dirout.\n",
    "vtu_files = glob.glob(os.path.join(dirout, f\"{name}_*.vtu\"))\n",
    "\n",
    "if not vtu_files:\n",
    "    raise ValueError(f\"No VTU files matching '{name}_*.vtu' found in the directory: {dirout}\")\n",
    "\n",
    "# Function to extract the sequence number from a filename.\n",
    "def extract_seq(filename):\n",
    "    basename = os.path.basename(filename)\n",
    "    match = re.search(r'_(\\d+)\\.vtu$', basename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        # Return -1 if the file doesn't match the expected pattern.\n",
    "        return -1\n",
    "\n",
    "# Find the file with the maximum sequence number.\n",
    "latest_vtu_file = max(vtu_files, key=extract_seq)\n",
    "print(\"The latest VTU file is:\", latest_vtu_file)\n",
    "\n",
    "# Use the found file directly as the result filename.\n",
    "ResFName = latest_vtu_file\n",
    "\n",
    "# ---------------------------\n",
    "# Read the VTU file using VTK and extract point data including 'source'\n",
    "# ---------------------------\n",
    "reader = vtk.vtkXMLUnstructuredGridReader()\n",
    "reader.SetFileName(ResFName)\n",
    "reader.Update()\n",
    "data = reader.GetOutput()\n",
    "\n",
    "points = data.GetPoints()\n",
    "num_points = points.GetNumberOfPoints()\n",
    "\n",
    "# Extract the 'source' field from point data.\n",
    "source_field = data.GetPointData().GetArray(\"source\")\n",
    "if source_field is None:\n",
    "    raise ValueError(\"No 'source' field found in the point data!\")\n",
    "\n",
    "lons, lats, sources = [], [], []\n",
    "for i in range(num_points):\n",
    "    point = points.GetPoint(i)\n",
    "    lons.append(point[0]) \n",
    "    lats.append(point[1])\n",
    "    src_val = source_field.GetValue(i)\n",
    "    sources.append(src_val)\n",
    "\n",
    "unique_sources = sorted(set(sources))\n",
    "nunique = len(unique_sources)\n",
    "print(\"Unique sources:\", unique_sources)\n",
    "\n",
    "# Use Matplotlib's \"Dark2\" colormap for a set of high-contrast colors.\n",
    "cmap_dark2 = plt.get_cmap('Dark2')\n",
    "colors_dark2 = [mpl.colors.rgb2hex(cmap_dark2(i)) for i in range(cmap_dark2.N)]\n",
    "# If there are more sources than colors, cycle through the colormap:\n",
    "colors_list = [colors_dark2[i % len(colors_dark2)] for i in range(nunique)]\n",
    "color_mapping = {source: color for source, color in zip(unique_sources, colors_list)}\n",
    "\n",
    "# ---------------------------\n",
    "# Create a Folium map with a length scale and a measuring ruler.\n",
    "# ---------------------------\n",
    "center = [sum(lats) / len(lats), sum(lons) / len(lons)]\n",
    "map_vtu = folium.Map(location=center, zoom_start=4, control_scale=True)\n",
    "\n",
    "measure_control = MeasureControl(\n",
    "    position=\"topleft\",\n",
    "    primary_length_unit=\"meters\",\n",
    "    secondary_length_unit=\"miles\",\n",
    "    active_color=\"red\",\n",
    "    completed_color=\"green\"\n",
    ")\n",
    "map_vtu.add_child(measure_control)\n",
    "\n",
    "# ---------------------------\n",
    "# Add colored markers for each point.\n",
    "# ---------------------------\n",
    "for lat, lon, src in zip(lats, lons, sources):\n",
    "    color = color_mapping.get(src, \"black\")\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=1,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"Source: {src}\"\n",
    "    ).add_to(map_vtu)\n",
    "\n",
    "map_vtu.save(os.path.join(dirout, \"map_vtu.html\"))\n",
    "print(\"Map saved as map_vtu.html\")\n",
    "\n",
    "# Display the map inline in a Jupyter Notebook (if applicable)\n",
    "map_vtu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
